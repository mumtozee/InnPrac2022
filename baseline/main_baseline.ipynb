{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, DataCollatorForLanguageModeling, TrainingArguments, Trainer\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <h3>Prepare dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/miniconda3/envs/innprac37/lib/python3.7/site-packages/cryptography/hazmat/backends/openssl/x509.py:17: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
      "  utils.DeprecatedIn35,\n",
      "Using custom data configuration default-d87bd31fe63ad7c9\n",
      "Reusing dataset csv (/home/admin/.cache/huggingface/datasets/csv/default-d87bd31fe63ad7c9/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "972c01e1252e4afd9b65f5cb0b7cf657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['history', 'response', 'da'],\n",
       "        num_rows: 76052\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['history', 'response', 'da'],\n",
       "        num_rows: 7069\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['history', 'response', 'da'],\n",
       "        num_rows: 6740\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_files = {\n",
    "  \"train\": \"./data/da_prompts/train.csv\",\n",
    "  \"val\": \"./data/da_prompts/val.csv\",\n",
    "  \"test\": \"./data/da_prompts/test.csv\",\n",
    "}\n",
    "dd = load_dataset(\"csv\", data_files=data_files, sep=';')\n",
    "dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the tokenizer and add special tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([50256, 50261, 50257, 50258, 50259, 50260], 50257)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toker = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-small\")\n",
    "toker.add_special_tokens({\n",
    "  \"additional_special_tokens\": [\"[DA_1]\", \"[DA_2]\", \"[DA_3]\", \"[DA_4]\"],\n",
    "  \"pad_token\": \"[PAD]\"\n",
    "})\n",
    "toker.all_special_ids, toker.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(example):\n",
    "  return toker(\n",
    "      [x + \" \" + y for x, y in zip(example['history'], example['response'])],\n",
    "      padding=True,\n",
    "      truncation=True,\n",
    "      max_length=128\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/admin/.cache/huggingface/datasets/csv/default-d87bd31fe63ad7c9/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-6d6464599fdf2082.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/admin/.cache/huggingface/datasets/csv/default-d87bd31fe63ad7c9/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-854fba7d9f3ab7d7.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/admin/.cache/huggingface/datasets/csv/default-d87bd31fe63ad7c9/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-d68fff71b174c7a1.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/admin/.cache/huggingface/datasets/csv/default-d87bd31fe63ad7c9/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-751ee030686a17e0.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/admin/.cache/huggingface/datasets/csv/default-d87bd31fe63ad7c9/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-ac81e407e5b9bf56.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/admin/.cache/huggingface/datasets/csv/default-d87bd31fe63ad7c9/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-89332f75ff668091.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/admin/.cache/huggingface/datasets/csv/default-d87bd31fe63ad7c9/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-3158c138ae918001.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/admin/.cache/huggingface/datasets/csv/default-d87bd31fe63ad7c9/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-b6bfe82ff436d58b.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/admin/.cache/huggingface/datasets/csv/default-d87bd31fe63ad7c9/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-cc3e3566247cb0e7.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/admin/.cache/huggingface/datasets/csv/default-d87bd31fe63ad7c9/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-046bd62f8e0bd3b5.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/admin/.cache/huggingface/datasets/csv/default-d87bd31fe63ad7c9/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-ea2b2ed59753aa41.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/admin/.cache/huggingface/datasets/csv/default-d87bd31fe63ad7c9/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-57edcedbab4a9301.arrow\n"
     ]
    }
   ],
   "source": [
    "enc_dd = dd.map(\n",
    "  tokenize,\n",
    "  batched=True,\n",
    "  num_proc=4,\n",
    "  remove_columns=dd[\"train\"].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need a data collator to pad data and get lm_labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = DataCollatorForLanguageModeling(\n",
    "  tokenizer=toker,\n",
    "  mlm=False,\n",
    "  pad_to_multiple_of=128\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test collator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[50259, 13816,   837,  5395,   837,   703,   546,  1016,   329,   257,\n",
       "           1178, 16800,   706,  8073,  5633,   220, 50256,   220, 50260,   220,\n",
       "            921,   760,   326,   318, 29850,   475,   318,  1107,   407,   922,\n",
       "            329,   674, 13547,   764,   220, 50256, 50261, 50261, 50261, 50261,\n",
       "          50261, 50261, 50261, 50261, 50261, 50261, 50261, 50261, 50261, 50261,\n",
       "          50261, 50261, 50261, 50261, 50261, 50261, 50261, 50261, 50261, 50261,\n",
       "          50261, 50261, 50261, 50261, 50261, 50261, 50261, 50261, 50261, 50261,\n",
       "          50261, 50261, 50261, 50261, 50261, 50261, 50261, 50261, 50261, 50261,\n",
       "          50261, 50261, 50261, 50261, 50261, 50261, 50261, 50261, 50261, 50261,\n",
       "          50261, 50261, 50261, 50261, 50261, 50261, 50261, 50261, 50261, 50261,\n",
       "          50261, 50261, 50261, 50261, 50261, 50261, 50261, 50261, 50261, 50261,\n",
       "          50261, 50261, 50261, 50261, 50261, 50261, 50261, 50261, 50261, 50261,\n",
       "          50261, 50261, 50261, 50261, 50261, 50261, 50261, 50261]]),\n",
       " tensor([[50259, 13816,   837,  5395,   837,   703,   546,  1016,   329,   257,\n",
       "           1178, 16800,   706,  8073,  5633,   220, 50256,   220, 50260,   220,\n",
       "            921,   760,   326,   318, 29850,   475,   318,  1107,   407,   922,\n",
       "            329,   674, 13547,   764,   220, 50256,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp1 = next(iter(enc_dd[\"train\"]))\n",
    "out = collator([tmp1])\n",
    "out[\"input_ids\"], out[\"labels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model and resize it's embedding space as we added 5 special tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/miniconda3/envs/innprac37/lib/python3.7/site-packages/cryptography/hazmat/backends/openssl/x509.py:17: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
      "  utils.DeprecatedIn35,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(50262, 768)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-small\")\n",
    "model.resize_token_embeddings(toker.vocab_size + 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <h3>Train the model:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = TrainingArguments(\n",
    "    output_dir=\"./models/results3\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=1e-5,\n",
    "    weight_decay=0.01,\n",
    "    save_steps=4000,\n",
    "    per_device_eval_batch_size=32,\n",
    "    per_device_train_batch_size=8\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    train_dataset=enc_dd[\"train\"],\n",
    "    eval_dataset=enc_dd[\"test\"],\n",
    "    data_collator=collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 76052\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 28521\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28521' max='28521' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28521/28521 1:29:05, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.152700</td>\n",
       "      <td>2.170343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.989400</td>\n",
       "      <td>2.119049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.935300</td>\n",
       "      <td>2.109156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./models/results3/checkpoint-4000\n",
      "Configuration saved in ./models/results3/checkpoint-4000/config.json\n",
      "Model weights saved in ./models/results3/checkpoint-4000/pytorch_model.bin\n",
      "Saving model checkpoint to ./models/results3/checkpoint-8000\n",
      "Configuration saved in ./models/results3/checkpoint-8000/config.json\n",
      "Model weights saved in ./models/results3/checkpoint-8000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6740\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./models/results3/checkpoint-12000\n",
      "Configuration saved in ./models/results3/checkpoint-12000/config.json\n",
      "Model weights saved in ./models/results3/checkpoint-12000/pytorch_model.bin\n",
      "Saving model checkpoint to ./models/results3/checkpoint-16000\n",
      "Configuration saved in ./models/results3/checkpoint-16000/config.json\n",
      "Model weights saved in ./models/results3/checkpoint-16000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6740\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to ./models/results3/checkpoint-20000\n",
      "Configuration saved in ./models/results3/checkpoint-20000/config.json\n",
      "Model weights saved in ./models/results3/checkpoint-20000/pytorch_model.bin\n",
      "Saving model checkpoint to ./models/results3/checkpoint-24000\n",
      "Configuration saved in ./models/results3/checkpoint-24000/config.json\n",
      "Model weights saved in ./models/results3/checkpoint-24000/pytorch_model.bin\n",
      "Saving model checkpoint to ./models/results3/checkpoint-28000\n",
      "Configuration saved in ./models/results3/checkpoint-28000/config.json\n",
      "Model weights saved in ./models/results3/checkpoint-28000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6740\n",
      "  Batch size = 32\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=28521, training_loss=2.1548138021239933, metrics={'train_runtime': 5346.1678, 'train_samples_per_second': 42.677, 'train_steps_per_second': 5.335, 'total_flos': 1.4903836213248e+16, 'train_loss': 2.1548138021239933, 'epoch': 3.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./models/results3/baseline\n",
      "Configuration saved in ./models/results3/baseline/config.json\n",
      "Model weights saved in ./models/results3/baseline/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_state()\n",
    "trainer.save_model(\"./models/results3/baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in ./models/results3/baseline/tokenizer/tokenizer_config.json\n",
      "Special tokens file saved in ./models/results3/baseline/tokenizer/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./models/results3/baseline/tokenizer/tokenizer_config.json',\n",
       " './models/results3/baseline/tokenizer/special_tokens_map.json',\n",
       " './models/results3/baseline/tokenizer/vocab.json',\n",
       " './models/results3/baseline/tokenizer/merges.txt',\n",
       " './models/results3/baseline/tokenizer/added_tokens.json',\n",
       " './models/results3/baseline/tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toker.save_pretrained(\"./models/results3/baseline/tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <h3>Evaluate the model:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50262, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50262, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = AutoModelForCausalLM.from_pretrained(\"./models/results3/baseline\")\n",
    "model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='./models/results3/baseline/tokenizer', vocab_size=50257, model_max_len=1024, is_fast=True, padding_side='right', special_tokens={'bos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': '[PAD]', 'additional_special_tokens': ['[DA_1]', '[DA_2]', '[DA_3]', '[DA_4]']})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toker_2 = AutoTokenizer.from_pretrained(\"./models/results3/baseline/tokenizer\")\n",
    "toker_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(net, eval_batches, eval_len):\n",
    "  net.eval()\n",
    "  net.cuda()\n",
    "  eval_loss = 0.0\n",
    "  nb_eval_steps = 0\n",
    "  eval_batch_size = 32\n",
    "  for i in tqdm(range(0, eval_len, eval_batch_size)):\n",
    "    X, y = eval_batches[\"input_ids\"][i: i +\n",
    "                                    eval_batch_size], eval_batches[\"labels\"][i: i + eval_batch_size]\n",
    "    with torch.no_grad():\n",
    "      output = net(X.cuda(), labels=y.cuda())\n",
    "      lm_loss = output[0]\n",
    "      eval_loss += lm_loss.mean().item()\n",
    "    nb_eval_steps += 1\n",
    "  eval_loss = eval_loss / nb_eval_steps\n",
    "  ppl = torch.exp(torch.tensor(eval_loss))\n",
    "  return eval_loss, ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7069"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batches = collator([x for x in enc_dd[\"val\"]])\n",
    "test_len = len(test_batches[next(iter(test_batches.keys()))])\n",
    "test_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e4fc8b819748beae39290289e5be61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/221 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2.1092151721678167, tensor(8.2418))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model(model, test_batches, test_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a18229762424436b4cac8ed2d0a70cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/221 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2.1092151721678167, tensor(8.2418))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cpu()\n",
    "eval_model(model_2, test_batches, test_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50262, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50262, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_response(net, tokenizer, inp):\n",
    "  net.cuda()\n",
    "  net.eval()\n",
    "  input_ids = tokenizer.encode(inp, return_tensors='pt')\n",
    "  response_ids = net.generate(\n",
    "    input_ids.cuda(),\n",
    "    max_length=500,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    top_p=0.92,\n",
    "    top_k=50\n",
    "  )\n",
    "  response = tokenizer.decode(\n",
    "    response_ids[:, input_ids.shape[-1]:][0],\n",
    "    skip_special_tokens=True\n",
    "  )\n",
    "  net.cpu()\n",
    "  return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" I'm fine. How about yourself? \""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_response(model_2, toker_2, f\"[DA_1] hello{toker_2.eos_token}[DA_2] Hi, how are you ?{toker_2.eos_token}[DA_2] \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preporcess the validation set to evaulate generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_LEN = 7\n",
    "\n",
    "def move_prefixes(batch):\n",
    "  histories = batch['history']\n",
    "  responses = batch['response']\n",
    "  for i in range(len(histories)):\n",
    "    histories[i] = \"\".join([histories[i], responses[i][:PROMPT_LEN]])\n",
    "    responses[i] = responses[i][PROMPT_LEN:]\n",
    "  batch[\"history\"] = histories\n",
    "  batch[\"response\"] = responses\n",
    "  return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2efc55a3ce784fac9fb12a830eda2fab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['history', 'response', 'da'],\n",
       "    num_rows: 7069\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_set = dd[\"val\"].map(\n",
    "  move_prefixes,\n",
    "  batched=True\n",
    ")\n",
    "val_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7069"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_set.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Well , that's too far.Can you change some money for me ? <|endoftext|>\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(val_set)\n",
    "df.iloc[1][\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_df = df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_answers(df: pd.DataFrame, output_path, model=model_2, toker=toker_2):\n",
    "  model_answers = []\n",
    "  for i in tqdm(range(df.shape[0])):\n",
    "    model_answers.append(gen_response(\n",
    "      model, \n",
    "      toker,\n",
    "      df.iloc[i][\"history\"]\n",
    "    ))\n",
    "  df[\"model_answer\"] = model_answers\n",
    "  df.rename(columns={\"response\": \"gold_answer\", \"da\": \"meta\"}, inplace=True)\n",
    "  print(f\"Saving to {output_path}\")\n",
    "  with open(output_path, \"w+\") as f:\n",
    "    df.to_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3bcb1b6eb0743cd8ea7d83fdfb62cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7069 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input length of input_ids is 502, but ``max_length`` is set to 500.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Input length of input_ids is 576, but ``max_length`` is set to 500.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Input length of input_ids is 599, but ``max_length`` is set to 500.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Input length of input_ids is 659, but ``max_length`` is set to 500.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Input length of input_ids is 677, but ``max_length`` is set to 500.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Input length of input_ids is 697, but ``max_length`` is set to 500.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Input length of input_ids is 735, but ``max_length`` is set to 500.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Input length of input_ids is 545, but ``max_length`` is set to 500.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Input length of input_ids is 559, but ``max_length`` is set to 500.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Input length of input_ids is 580, but ``max_length`` is set to 500.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Input length of input_ids is 630, but ``max_length`` is set to 500.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n",
      "Input length of input_ids is 646, but ``max_length`` is set to 500.This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to ./results/baseline3.csv\n"
     ]
    }
   ],
   "source": [
    "save_model_answers(df, \"./results/baseline3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>history</th>\n",
       "      <th>gold_answer</th>\n",
       "      <th>meta</th>\n",
       "      <th>model_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[DA_2] Good morning , sir . Is there a bank ne...</td>\n",
       "      <td>There is one . 5 blocks away from here ? &lt;|en...</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes, there is.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[DA_2] Good morning , sir . Is there a bank ne...</td>\n",
       "      <td>Well , that's too far.Can you change some mon...</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes, please. I'd like to withdraw some money.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[DA_2] Good morning , sir . Is there a bank ne...</td>\n",
       "      <td>Surely , of course . What kind of currency ha...</td>\n",
       "      <td>2</td>\n",
       "      <td>Sure. What kind of money do you want?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[DA_2] Good morning , sir . Is there a bank ne...</td>\n",
       "      <td>RIB . &lt;|endoftext|&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>I have a US dollar note.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[DA_2] Good morning , sir . Is there a bank ne...</td>\n",
       "      <td>How much would you like to change ? &lt;|endofte...</td>\n",
       "      <td>2</td>\n",
       "      <td>How much is it?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7064</th>\n",
       "      <td>[DA_2] Welcome , sir . What can I do for you ?...</td>\n",
       "      <td>Oh , it must be very precious . Is it breakab...</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the name of the tea set?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7065</th>\n",
       "      <td>[DA_2] Welcome , sir . What can I do for you ?...</td>\n",
       "      <td>No , if you take some care when you use them ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes, sir.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7066</th>\n",
       "      <td>[DA_2] Welcome , sir . What can I do for you ?...</td>\n",
       "      <td>How much is it ? &lt;|endoftext|&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>What about the handle?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7067</th>\n",
       "      <td>[DA_2] Welcome , sir . What can I do for you ?...</td>\n",
       "      <td>Two thousand . &lt;|endoftext|&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>It's only $ 2.50.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7068</th>\n",
       "      <td>[DA_2] Welcome , sir . What can I do for you ?...</td>\n",
       "      <td>Oh , it is beyond my purse . &lt;|endoftext|&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>That's a lot.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7069 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                history  \\\n",
       "0     [DA_2] Good morning , sir . Is there a bank ne...   \n",
       "1     [DA_2] Good morning , sir . Is there a bank ne...   \n",
       "2     [DA_2] Good morning , sir . Is there a bank ne...   \n",
       "3     [DA_2] Good morning , sir . Is there a bank ne...   \n",
       "4     [DA_2] Good morning , sir . Is there a bank ne...   \n",
       "...                                                 ...   \n",
       "7064  [DA_2] Welcome , sir . What can I do for you ?...   \n",
       "7065  [DA_2] Welcome , sir . What can I do for you ?...   \n",
       "7066  [DA_2] Welcome , sir . What can I do for you ?...   \n",
       "7067  [DA_2] Welcome , sir . What can I do for you ?...   \n",
       "7068  [DA_2] Welcome , sir . What can I do for you ?...   \n",
       "\n",
       "                                            gold_answer  meta  \\\n",
       "0      There is one . 5 blocks away from here ? <|en...     1   \n",
       "1      Well , that's too far.Can you change some mon...     3   \n",
       "2      Surely , of course . What kind of currency ha...     2   \n",
       "3                                   RIB . <|endoftext|>     1   \n",
       "4      How much would you like to change ? <|endofte...     2   \n",
       "...                                                 ...   ...   \n",
       "7064   Oh , it must be very precious . Is it breakab...     2   \n",
       "7065   No , if you take some care when you use them ...     1   \n",
       "7066                     How much is it ? <|endoftext|>     2   \n",
       "7067                       Two thousand . <|endoftext|>     1   \n",
       "7068         Oh , it is beyond my purse . <|endoftext|>     1   \n",
       "\n",
       "                                         model_answer  \n",
       "0                                     Yes, there is.   \n",
       "1      Yes, please. I'd like to withdraw some money.   \n",
       "2              Sure. What kind of money do you want?   \n",
       "3                           I have a US dollar note.   \n",
       "4                                    How much is it?   \n",
       "...                                               ...  \n",
       "7064                What is the name of the tea set?   \n",
       "7065                                       Yes, sir.   \n",
       "7066                          What about the handle?   \n",
       "7067                               It's only $ 2.50.   \n",
       "7068                                   That's a lot.   \n",
       "\n",
       "[7069 rows x 4 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0c1bfc040c8730cbad4faf7377a613dba97918ee4b58dbc69c3143dc60c27424"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('innprac37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
